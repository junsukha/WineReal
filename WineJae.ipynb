{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Formula to best wine\n",
    "### Attempt of finding a model that relates multiple factors of wine and quality (subjective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read into 2D list then convert to numpy matrix\n",
    "database = []\n",
    "dataheader = 0\n",
    "DATA_SIZE = 5000\n",
    "\n",
    "with open('winequality-red.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    dataheader = spamreader.__next__()\n",
    "    counter = 0\n",
    "    for row in spamreader:\n",
    "        row = np.asarray(row).astype(np.float64)\n",
    "        database.append(row)\n",
    "        counter += 1\n",
    "        if counter > DATA_SIZE:\n",
    "            break\n",
    "# print(np.matrix(database))\n",
    "database = np.matrix(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into test and train data\n",
    "# Then do ridge regression\n",
    "test_size = database.shape[0] // 8\n",
    "train_size = database.shape[0] - test_size\n",
    "train_data, test_data = np.vsplit(database, np.array([train_size]))\n",
    "\n",
    "train_x, train_y = np.hsplit(train_data, np.array([len(dataheader)-1]))\n",
    "test_x, test_y = np.hsplit(test_data, np.array([len(dataheader)-1]))\n",
    "\n",
    "rd = Ridge().fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36865507887691423\n"
     ]
    }
   ],
   "source": [
    "# Display score\n",
    "print(rd.score(train_x, train_y))\n",
    "# print(lr.score(test_x, test_y))\n",
    "\n",
    "# \n",
    "# Currently, score (R2) is really low\n",
    "# This is probably due to not having enough data size compared to having lots of columns\n",
    "# To get more meaningful \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Identify good wine\n",
    "### By using same quality, classify wine into two categories: normal, and good(quality score 7 or above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1],[2],[3]])\n",
    "# x = x.flatten()\n",
    "x.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.4    0.7    0.    ...  0.56   9.4    5.   ]\n",
      " [ 7.8    0.88   0.    ...  0.68   9.8    5.   ]\n",
      " [ 7.8    0.76   0.04  ...  0.65   9.8    5.   ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  0.75  11.     6.   ]\n",
      " [ 5.9    0.645  0.12  ...  0.71  10.2    5.   ]\n",
      " [ 6.     0.31   0.47  ...  0.66  11.     6.   ]]\n",
      "[[ 7.4    0.7    0.    ...  3.51   0.56   9.4  ]\n",
      " [ 7.8    0.88   0.    ...  3.2    0.68   9.8  ]\n",
      " [ 7.8    0.76   0.04  ...  3.26   0.65   9.8  ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  3.42   0.75  11.   ]\n",
      " [ 5.9    0.645  0.12  ...  3.57   0.71  10.2  ]\n",
      " [ 6.     0.31   0.47  ...  3.39   0.66  11.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(database)\n",
    "#refer to the website below\n",
    "#https://stackabuse.com/classification-in-python-with-scikit-learn-and-pandas/\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "y = database[:,-1]\n",
    "#converting the shape of y into 1d. \n",
    "#can you find a shorter way to convert it? Need to make (size,) not (1,size)\n",
    "y = np.array(y)\n",
    "y = y.ravel()\n",
    "\n",
    "X = database[:,:-1]\n",
    "print(X)\n",
    "# print(X.shape, y.shape)\n",
    "NN = MLPClassifier(solver = 'lbfgs', alpha = 1e-5, hidden_layer_sizes = (100,100), random_state = 1, max_iter=1000)\n",
    "NN.fit(X,y)\n",
    "print(NN.predict(X[1590:,:]))\n",
    "round(NN.score(X,y), 4)\n",
    "#the predicted quality scores don't seem to match with the original data.\n",
    "#if you increase hidden_layer_sizes, the score incresase also, which makes sense\n",
    "#but still, the last 10 predictions always show all 6's.\n",
    "#edit: manipulate max_iter and get hight score(more precise prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# use binary classification\n",
    "# \n",
    "\n",
    "#this one is crap\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load dataset\n",
    "dataframe = read_csv(\"winequality-red.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# baseline model\n",
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(60, input_dim=60, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# evaluate baseline model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
